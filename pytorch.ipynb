{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: music21 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (7.3.3)\n",
      "Requirement already satisfied: matplotlib in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (3.5.2)\n",
      "Requirement already satisfied: jsonpickle in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (2.2.0)\n",
      "Requirement already satisfied: joblib in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (1.1.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (1.12)\n",
      "Requirement already satisfied: numpy in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (1.22.4)\n",
      "Requirement already satisfied: more-itertools in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (8.13.0)\n",
      "Requirement already satisfied: chardet in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from music21) (5.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib->music21) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n",
      "Requirement already satisfied: pyblaze in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn<0.25.0,>=0.23.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (0.24.2)\n",
      "Requirement already satisfied: tensorboard<3.0.0,>=2.2.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (2.9.1)\n",
      "Requirement already satisfied: numba<1.0.0,>=0.48.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (0.55.2)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (3.5.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.4.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (1.8.1)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.4.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (1.12.0+cu116)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.2 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyblaze) (1.22.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->pyblaze) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from numba<1.0.0,>=0.48.0->pyblaze) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from numba<1.0.0,>=0.48.0->pyblaze) (61.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->pyblaze) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from scikit-learn<0.25.0,>=0.23.0->pyblaze) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from scikit-learn<0.25.0,>=0.23.0->pyblaze) (1.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (1.47.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (3.3.7)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (1.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (3.19.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from tensorboard<3.0.0,>=2.2.0->pyblaze) (2.9.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.2.0->pyblaze) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.2.0->pyblaze) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.2.0->pyblaze) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3.0.0,>=2.2.0->pyblaze) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<3.0.0,>=2.2.0->pyblaze) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3.0.0,>=2.2.0->pyblaze) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.2.0->pyblaze) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.2.0->pyblaze) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.2.0->pyblaze) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.2.0->pyblaze) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.2.0->pyblaze) (2.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3.0.0,>=2.2.0->pyblaze) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages (from torch<2.0.0,>=1.4.0->pyblaze) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install music21\n",
    "!pip install pyblaze\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d blanderbuss/midi-classic-music\n",
    "# !mkdir -p dataset\n",
    "# !unzip -o -qq midi-classic-music.zip -d dataset\n",
    "# !unzip -o -qq midiclassics.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from parse import create_dataset\n",
    "from parse import convert_offsets_to_waits, get_score_with_components, tokenize_score\n",
    "from matplotlib import pyplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'parse' from '/home/jakub/neural music/parse.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import parse\n",
    "importlib.reload(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"dataset_bach.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [convert_offsets_to_waits(dataset[file]) for file in dataset.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"dataset_bach_waits.npz\", *files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bach_waits = np.load(\"dataset_bach_waits.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = np.concatenate([dataset_bach_waits[file] for file in dataset.files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      0,   4800,  20505,      0,   4531,      0,  16623,\n",
       "        11215,      0,  13790,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0, 328328,      0,      0,      0,      0,  20428,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "         4573,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0, 160068,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,   3364,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,   4835,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,  25723,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,    876,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "         3651,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,    948])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatcmp = get_score_with_components(flat)\n",
    "np.bincount(flatcmp[flatcmp[:, 1] == 1][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(flatcmp[flatcmp[:, 1] == 1][:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.00000e+00, 1.90000e+01, 4.03000e+02, 2.64400e+03, 7.60600e+03,\n",
       "        1.82500e+04, 4.64210e+04, 6.77810e+04, 1.46203e+05, 1.25237e+05,\n",
       "        1.95448e+05, 2.00916e+05, 2.80442e+05, 2.64621e+05, 1.97663e+05,\n",
       "        5.72870e+04, 1.20820e+04, 1.21400e+03, 4.50000e+02, 2.60000e+01]),\n",
       " array([ 12. ,  16.5,  21. ,  25.5,  30. ,  34.5,  39. ,  43.5,  48. ,\n",
       "         52.5,  57. ,  61.5,  66. ,  70.5,  75. ,  79.5,  84. ,  88.5,\n",
       "         93. ,  97.5, 102. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(flatcmp[flatcmp[:, 1] == 0][:, 0], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 25305.,  21154.,  25005.,      0., 348756., 168005.,  30558.,\n",
       "           876.,   3651.,    948.]),\n",
       " array([1.09861229, 1.61041167, 2.12221105, 2.63401043, 3.14580981,\n",
       "        3.65760919, 4.16940858, 4.68120796, 5.19300734, 5.70480672,\n",
       "        6.2166061 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(np.log1p(flatcmp[flatcmp[:, 1] == 1][:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_score(flatcmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [tokenize_score(get_score_with_components(dataset_bach_waits[file])) for file in dataset_bach_waits.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"dataset_bach_tokenized.npz\", *files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 51., 55.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.48125e+05, 1.00000e+00, 2.50000e+01, 1.37700e+03, 9.27600e+03,\n",
       "        4.61000e+04, 1.27908e+05, 2.29884e+05, 2.87402e+05, 3.89404e+05,\n",
       "        4.20478e+05, 1.06575e+05, 5.81400e+03, 4.70000e+02, 6.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 4.80000e+03, 4.15420e+05, 2.04038e+05]),\n",
       " array([  0. ,   7.2,  14.4,  21.6,  28.8,  36. ,  43.2,  50.4,  57.6,\n",
       "         64.8,  72. ,  79.2,  86.4,  93.6, 100.8, 108. , 115.2, 122.4,\n",
       "        129.6, 136.8, 144. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_files = np.concatenate(files)\n",
    "pyplot.hist(all_files, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from compressive_transformer_pytorch import CompressiveTransformer\n",
    "from compressive_transformer_pytorch import AutoregressiveWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpressiveTransformer(CompressiveTransformer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.to_logits.add_module(\"softmax\", torch.nn.Softmax(-1))\n",
    "    # def forward(self, x, memories = None, mask = None):\n",
    "    #     out, mem, aux_loss = super().forward(x, memories, mask)\n",
    "    #     return torch.nn.Softmax()(out), mem, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CompressiveTransformer(\n",
    "    num_tokens = 128 + 16 + 1,\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    seq_len = 1024,\n",
    "    mem_len = 1024,\n",
    "    cmem_len = 256,\n",
    "    cmem_ratio = 4,\n",
    "    memory_layers = [5,6],\n",
    "    mogrify_gru=False,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181756928"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.generate(torch.ones(1, 1).to(torch.int64).cuda(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "def generate_dataset(path=\"dataset_bach_tokenized.npz\", batch_len=16):\n",
    "\tfiles = np.load(path)\n",
    "\twhile True:\n",
    "\t\tX = []\n",
    "\t\tY = []\n",
    "\t\tfor _ in range(batch_len):\n",
    "\t\t\tfile = files[choice(files.files)]\n",
    "\t\t\tnum = np.random.randint(0, len(file) - 1024)\n",
    "\t\t\tX.append(file[num: num+1024].tolist())\n",
    "\t\t\tY.append(file[num+1024])\n",
    "\t\tyield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generate_dataset(batch_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1024), (2,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(gen)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ..., 65., 60., 53.],\n",
       "       [ 0.,  0.,  0., ..., 68., 61., 61.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141., 141.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_regr = AutoregressiveWrapper(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = torch.from_numpy(next(gen)[0]).to(torch.int).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 17 11:45:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   64C    P0     9W /  N/A |    712MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1145      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A      4180      C   ...da3/envs/torch/bin/python      705MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 3.82 GiB total capacity; 2.74 GiB already allocated; 24.06 MiB free; 2.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jakub/neural music/pytorch.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jakub/neural%20music/pytorch.ipynb#ch0000033?line=0'>1</a>\u001b[0m tens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(\u001b[39mnext\u001b[39m(gen)[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jakub/neural%20music/pytorch.ipynb#ch0000033?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m model(tens)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:382\u001b[0m, in \u001b[0;36mCompressiveTransformer.forward\u001b[0;34m(self, x, memories, mask)\u001b[0m\n\u001b[1;32m    379\u001b[0m use_memory \u001b[39m=\u001b[39m layer_num \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_layers\n\u001b[1;32m    380\u001b[0m memories \u001b[39m=\u001b[39m (\u001b[39mnext\u001b[39m(mem_iter), \u001b[39mnext\u001b[39m(cmem_iter)) \u001b[39mif\u001b[39;00m use_memory \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m x, (mem_out, cmem_out), layer_aux_loss \u001b[39m=\u001b[39m attn(x, memories \u001b[39m=\u001b[39;49m memories, calc_memory \u001b[39m=\u001b[39;49m use_memory, input_mask \u001b[39m=\u001b[39;49m mask, pos_emb \u001b[39m=\u001b[39;49m pos_emb)\n\u001b[1;32m    383\u001b[0m x,  \u001b[39m=\u001b[39m ff(x)\n\u001b[1;32m    385\u001b[0m aux_loss \u001b[39m=\u001b[39m aux_loss \u001b[39m+\u001b[39m layer_aux_loss\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:102\u001b[0m, in \u001b[0;36mGRUGating.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    101\u001b[0m     batch, dim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim\n\u001b[0;32m--> 102\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    103\u001b[0m     (y, \u001b[39m*\u001b[39mrest) \u001b[39m=\u001b[39m cast_tuple(out)\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:124\u001b[0m, in \u001b[0;36mPreNorm.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    123\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:223\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[0;34m(self, x, memories, pos_emb, input_mask, calc_memory, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     pos_emb \u001b[39m=\u001b[39m pos_emb[:, \u001b[39m-\u001b[39mkv_len:]\u001b[39m.\u001b[39mtype(q\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    222\u001b[0m     pos_dots \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mbhid,hjd->bhij\u001b[39m\u001b[39m'\u001b[39m, q, pos_emb) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\n\u001b[0;32m--> 223\u001b[0m     pos_dots \u001b[39m=\u001b[39m shift(pos_dots)\n\u001b[1;32m    224\u001b[0m     dots \u001b[39m=\u001b[39m dots \u001b[39m+\u001b[39m pos_dots\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m input_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:62\u001b[0m, in \u001b[0;36mshift\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     60\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39m_, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     61\u001b[0m zero_pad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39m*\u001b[39m_, \u001b[39m-\u001b[39mx\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m l, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto(x))\n\u001b[0;32m---> 62\u001b[0m shifted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x, zero_pad], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39m_, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, l)\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m shifted[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :i, i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 3.82 GiB total capacity; 2.74 GiB already allocated; 24.06 MiB free; 2.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "tens = torch.from_numpy(next(gen)[0]).to(torch.int).cuda()\n",
    "x = model(tens)\n",
    "# loss, aux_loss, _ = model_regr(torch.from_numpy(np.array([x[0]])).to(torch.int64).cuda(), return_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.00 GiB (GPU 0; 3.82 GiB total capacity; 2.36 GiB already allocated; 582.06 MiB free; 2.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jakub/neural music/pytorch.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jakub/neural%20music/pytorch.ipynb#ch0000036?line=0'>1</a>\u001b[0m model_regr\u001b[39m.\u001b[39;49mgenerate(torch\u001b[39m.\u001b[39;49mones(\u001b[39m16\u001b[39;49m, \u001b[39m1024\u001b[39;49m)\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mint64)\u001b[39m.\u001b[39;49mcuda(), \u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/autoregressive_wrapper.py:81\u001b[0m, in \u001b[0;36mAutoregressiveWrapper.generate\u001b[0;34m(self, start_tokens, seq_len, eos_token, temperature, filter_logits_fn, filter_thres, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m input_len \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_len):\n\u001b[0;32m---> 81\u001b[0m     logits, mem, aux_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(out[:, \u001b[39m-\u001b[39;49minput_len:], memories \u001b[39m=\u001b[39;49m mem, mask \u001b[39m=\u001b[39;49m mask[:, \u001b[39m-\u001b[39;49minput_len:], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     82\u001b[0m     logits \u001b[39m=\u001b[39m logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     83\u001b[0m     filtered_logits \u001b[39m=\u001b[39m filter_logits_fn(logits, thres \u001b[39m=\u001b[39m filter_thres)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:382\u001b[0m, in \u001b[0;36mCompressiveTransformer.forward\u001b[0;34m(self, x, memories, mask)\u001b[0m\n\u001b[1;32m    379\u001b[0m use_memory \u001b[39m=\u001b[39m layer_num \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_layers\n\u001b[1;32m    380\u001b[0m memories \u001b[39m=\u001b[39m (\u001b[39mnext\u001b[39m(mem_iter), \u001b[39mnext\u001b[39m(cmem_iter)) \u001b[39mif\u001b[39;00m use_memory \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m x, (mem_out, cmem_out), layer_aux_loss \u001b[39m=\u001b[39m attn(x, memories \u001b[39m=\u001b[39;49m memories, calc_memory \u001b[39m=\u001b[39;49m use_memory, input_mask \u001b[39m=\u001b[39;49m mask, pos_emb \u001b[39m=\u001b[39;49m pos_emb)\n\u001b[1;32m    383\u001b[0m x,  \u001b[39m=\u001b[39m ff(x)\n\u001b[1;32m    385\u001b[0m aux_loss \u001b[39m=\u001b[39m aux_loss \u001b[39m+\u001b[39m layer_aux_loss\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:102\u001b[0m, in \u001b[0;36mGRUGating.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    101\u001b[0m     batch, dim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim\n\u001b[0;32m--> 102\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    103\u001b[0m     (y, \u001b[39m*\u001b[39mrest) \u001b[39m=\u001b[39m cast_tuple(out)\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:124\u001b[0m, in \u001b[0;36mPreNorm.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    123\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:223\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[0;34m(self, x, memories, pos_emb, input_mask, calc_memory, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     pos_emb \u001b[39m=\u001b[39m pos_emb[:, \u001b[39m-\u001b[39mkv_len:]\u001b[39m.\u001b[39mtype(q\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    222\u001b[0m     pos_dots \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mbhid,hjd->bhij\u001b[39m\u001b[39m'\u001b[39m, q, pos_emb) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\n\u001b[0;32m--> 223\u001b[0m     pos_dots \u001b[39m=\u001b[39m shift(pos_dots)\n\u001b[1;32m    224\u001b[0m     dots \u001b[39m=\u001b[39m dots \u001b[39m+\u001b[39m pos_dots\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m input_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py:62\u001b[0m, in \u001b[0;36mshift\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     60\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39m_, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     61\u001b[0m zero_pad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39m*\u001b[39m_, \u001b[39m-\u001b[39mx\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m l, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto(x))\n\u001b[0;32m---> 62\u001b[0m shifted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x, zero_pad], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39m_, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, l)\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m shifted[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :i, i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.00 GiB (GPU 0; 3.82 GiB total capacity; 2.36 GiB already allocated; 582.06 MiB free; 2.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model_regr.generate(torch.ones(16, 1024).to(torch.int64).cuda(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in np.load(\"dataset_bach_tokenized.npz\"):\n",
    "\tprint(file)\n",
    "\tmodel_regr.generate(torch.ones(1, 1).to(torch.int64).cuda(), 10)\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt step\n",
      "opt step\n"
     ]
    }
   ],
   "source": [
    "for loss, aux_loss, _ in model(inputs.to(torch.int64), return_loss = True):\n",
    "    print(\"opt step\")\n",
    "    (loss.sum() + aux_loss.sum()).backward()\n",
    "    # optimizer step and zero grad\n",
    "\n",
    "# ... after much training ...\n",
    "\n",
    "# generation is also greatly simplified and automated away\n",
    "# just pass in the prime, which can be 1 start token or any length\n",
    "# all is taken care of for you\n",
    "\n",
    "prime = torch.ones(1, 1).cuda().to(torch.int64)  # assume 1 is start token\n",
    "sample = model.generate(prime, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55d853517c1a7aa992c78b9209b384a18e46b6b84a2682acd8439b1a29fdf890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
